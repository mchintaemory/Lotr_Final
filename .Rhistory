pred.resp.univar <- PredictorResponseUnivar(fit = fit_int)
ggplot(pred.resp.univar, aes(z, est, ymin = est - 1.96 *se, ymax = est + 1.96*se)) +
geom_smooth(stat = "identity") +
facet_wrap(~variable) +
ylab("Outcome")+
ylab("Exposure")
risk.overall_int <- OverallRiskSummaries(fit = fit_int, y = mixture$LBXIN, Z = as.matrix(df.exp), X = as.matrix(df.cov),
qs = seq(0.25, 0.75, by = 0.05),
q.fixed = 0.5, method ="exact")
risk.overall_int <- OverallRiskSummaries(fit = fit_int, y = mixture$LBXIN, Z = as.matrix(df.exp), X = as.matrix(df.cov),
qs = seq(0.25, 0.75, by = 0.05),
q.fixed = 0.5, method ="exact")
risk.overall_int <- OverallRiskSummaries(
fit     = fit_int,
Z       = df.exp,
X       = df.cov,
qs      = seq(0.25, 0.75, by = 0.05),
q.fixed = 0.5,
method  = "approx"
)
risk.overall_int <- risk.overall_int %>%
dplyr::mutate(outcome = "LBXIN")
risk.overall_int
risk.overall_int <- risk.overall_int %>%
dplyr::mutate(outcome = "LBXIN")
ggplot(risk.overall_int, aes(quantile, est, ymin = est - 1.96*sd, ymax = est + 1.96*sd)) +
geom_pointrange()+
ylab("Estimate (95% Credible Interval)") +
xlab("Quantile")
pips_int <- ExtractPIPs(fit_int)
pips_int
#load in c
CHQ <- read_excel("C:/Users/mirra/OneDrive/Documents/Thesis/CHQ_dataset_040925.xlsx")
Sex_LifeStage <- read_excel("C:/Users/mirra/OneDrive/Documents/Thesis/Individual_IDs data_092225.xlsx")
GHQ <- read_excel("C:/Users/mirra/OneDrive/Documents/Thesis/GHQ_dataset_040925.xlsx")
GHQ_subset <- GHQ %>%
filter(!is.na(pbb_level))
#join by individual ids
Sex_LifeStage <- Sex_LifeStage %>%
rename(INDIVIDUAL_ID = Individual_ID)
cols <- setdiff(names(Sex_LifeStage), "INDIVIDUAL_ID")
# ---- join: add IDs columns onto CHQ by individual_id ----
chq_enhanced <- CHQ %>%
left_join(Sex_LifeStage, by = "INDIVIDUAL_ID")
#keep only women
chq_female <- chq_enhanced %>%
filter(sex_db == 2)
#only women with pbb levels
chq_subset <- chq_female %>%
filter(!is.na(LABID))
write.csv(chq_subset, "CHQ_subset_females_with_PBB.csv", row.names = FALSE)
chq_female %>%
group_by(repro_w_dr_ovarcyst) %>%
summarise(n = n()) %>%
arrange(desc(n))
chq_subset %>%
group_by(repro_w_dr_ovarcyst) %>%
summarise(n = n()) %>%
arrange(desc(n))
#GHQ_subset%>%
#  group_by(ovar_cyst) %>%
#  summarise(n = n()) %>%
#  arrange(desc(n))
# install.packages("pwr")  # if needed
library(pwr)
install.packages("pwr")  # if needed
library(pwr)
N    <- 365                 # total N
p0s  <- c(0.20)
RRs  <- c(1.2, 1.3, 1.5, 2.0)         # plausible RRs for high PBB
alpha <- 0.05
alternative <- "two.sided"            # use "greater" if strictly directional
q_grid <- seq(0.1, 0.9, by = 0.05)    # fraction high PBB (unknown)
pow_fun <- function(N, q, p0, p1, alpha=0.05, alt="two.sided"){
n_high <- max(2, round(q * N))
n_low  <- max(2, N - n_high)
pwr.2p2n.test(h = ES.h(p1, p0),
n1 = n_high, n2 = n_low,
sig.level = alpha, alternative = alt)$power
}
# Full grid across p0, RR, q
grid <- expand.grid(p0 = p0s, RR = RRs, q = q_grid)
grid$p1 <- pmin(grid$RR * grid$p0, 0.999)
grid$power <- mapply(function(p0, RR, q){
pow_fun(N, q, p0, min(RR*p0, 0.999), alpha, alternative)
}, grid$p0, grid$RR, grid$q)
# Best q (max power) and conservative power (min across q) by (p0, RR)
best_by_scenario <- do.call(rbind, lapply(split(grid, list(grid$p0, grid$RR)), function(df){
df[which.max(df$power), c("p0","RR","q","power")]
}))
row.names(best_by_scenario) <- NULL
conservative_by_scenario <- aggregate(power ~ p0 + RR, data = grid, FUN = min)
# Convenience views:
# 1) Power at q values you care about (e.g., 0.2, 0.3, 0.4)
subset_q <- subset(grid, q %in% c(0.2, 0.3, 0.4))
subset_q[order(subset_q$p0, subset_q$RR, subset_q$q), ]
# 2) Best q for each (p0, RR)
best_by_scenario[order(best_by_scenario$p0, best_by_scenario$RR), ]
# 3) Conservative (worst across q)
conservative_by_scenario[order(conservative_by_scenario$p0, conservative_by_scenario$RR), ]
library(pwr)
# -------- inputs you can edit --------
N          <- 365              # total sample size
p0         <- 0.20             # baseline prevalence in low PBB (reference)
RRs        <- c(1.2, 1.3, 1.5, 2.0)
alpha      <- 0.05
alternative<- "greater"        # one-sided test (high PBB > low PBB)
q_grid     <- seq(0.10, 0.90, by = 0.01)   # fraction in high PBB (unknown)
# -------------------------------------
p1_from_RR <- function(RR, p0) pmin(RR * p0, 0.999)
power_for <- function(N, q, p0, p1, alpha = 0.05, alt = "greater"){
n_high <- max(2, round(q * N))
n_low  <- max(2, N - n_high)
pwr.2p2n.test(h = ES.h(p1, p0),
n1 = n_high, n2 = n_low,
sig.level = alpha, alternative = alt)$power
}
# power across q, then pick best q per RR
grid <- do.call(rbind, lapply(RRs, function(RR){
p1 <- p1_from_RR(RR, p0)
data.frame(RR = RR, q = q_grid,
p1 = p1,
power = sapply(q_grid, function(q) power_for(N, q, p0, p1, alpha, alternative)))
}))
best <- grid[ave(grid$power, grid$RR, FUN=function(x) x==max(x))==1, ]
row.names(best) <- NULL
# Optional: power at specific q values you care about (e.g., 0.2, 0.3, 0.4)
power_at_q <- subset(grid, q %in% c(0.20, 0.30, 0.40))
power_at_q <- power_at_q[order(power_at_q$RR, power_at_q$q), ]
# Print tidy results
best_out <- within(best, {
power_pct <- round(100 * power, 1)
})
best_out
# ---- Generate narrative paragraph like your example ----
fmt_pct <- function(x) paste0(round(100*x, 0), "%")
fmt_pow <- function(x) paste0(round(100*x, 0), "%")
# Order by RR for the sentence
best_ordered <- best_out[order(best_out$RR), ]
parts <- mapply(function(RR, pwr)
sprintf("%s power for RR = %.1f", fmt_pow(pwr), RR),
best_ordered$power, best_ordered$RR)
library(survival)
PFOASur <- read.csv("C:/Users/mirra/Downloads/example5.csv")
Hazag <- coxph(Surv(survend2, dxB)-lnc8num + gender_f + C8HPage, data = PFOASur)
PFOASur <- read.csv("C:/Users/mirra/Downloads/example5.csv")
Hazag <- coxph(Surv(survend2, dxB)-lnc8num + gender_f + C8HPage, data = PFOASur)
library(survival)
PFOASur <- read.csv("C:/Users/mirra/Downloads/example5.csv")
#9b
Hazag <- coxph(Surv(survend2, dxB)-lnc8num + gender_f + C8HPage, data = PFOASur)
model.alcyes <- lm(LBXIN ~ URXOP1.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
library(readr)
library(bkmr)
library(ggplot2)
library(qgcomp)
install.packages("qgcompint")
library(qgcompint)
lab_activity_5 <-read_csv("C:/Users/mirra/OneDrive/Documents/EH562/eh562_lab_activities_nhanes.csv")
lab_activity_5<- lab_activity_5 %>%
mutate(URXOP1.log = log(URXOP1),
URXOP2.log = log(URXOP2),
URXOP3.log = log(URXOP3),
URXOP4.log = log(URXOP4),
URXOP5.log = log(URXOP5)
)
library(dplyr)
lab_activity_5 <-read_csv("C:/Users/mirra/OneDrive/Documents/EH562/eh562_lab_activities_nhanes.csv")
lab_activity_5<- lab_activity_5 %>%
mutate(URXOP1.log = log(URXOP1),
URXOP2.log = log(URXOP2),
URXOP3.log = log(URXOP3),
URXOP4.log = log(URXOP4),
URXOP5.log = log(URXOP5)
)
mixture <- lab_activity_5 %>% dplyr::select(URXOP1.log, URXOP2.log, URXOP3.log, URXOP4.log,
URXOP5.log, ALQ111, HIQ011, LBXIN)
mixture <- mixture[complete.cases(mixture), ]
nrow(mixture)
exposure.names <- c("URXOP1.log", "URXOP2.log", "URXOP3.log",
"URXOP4.log", "URXOP5.log")
#DMP
model.alcyes <- lm(LBXIN ~ URXOP1.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno <- lm(LBXIN ~ URXOP1.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes), 2)
round(confint(model.alcyes), 2)
round(coef(model.alcno), 2)
round(confint(model.alcno),2)
#DMP
model.alcyes <- lm(LBXIN ~ URXOP1.log,
data = mixture[which(mixture$ALQ111 == 1),]
)
model.alcno <- lm(LBXIN ~ URXOP1.log,
data = mixture[which(mixture$ALQ111 ==0),]
)
round(coef(model.alcyes), 2)
round(confint(model.alcyes), 2)
round(coef(model.alcno), 2)
round(confint(model.alcno),2)
model.alcyes2 <- lm(LBXIN ~ URXOP2.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno2 <- lm(LBXIN ~ URXOP2.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes2), 2)
round(confint(model.alcyes2), 2)
round(coef(model.alcno2), 2)
round(confint(model.alcno2),2)
model.alcyes4 <- lm(LBXIN ~ URXOP4.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno4 <- lm(LBXIN ~ URXOP4.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes4), 2)
round(confint(model.alcyes4), 2)
round(coef(model.alcno4), 2)
round(confint(model.alcno4),2)
#DMTP
model.alcyes3 <- lm(LBXIN ~ URXOP3.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno3 <- lm(LBXIN ~ URXOP3.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes3), 2)
round(confint(model.alcyes3), 2)
round(coef(model.alcno3), 2)
round(confint(model.alcno3),2)
#DETP
model.alcyes4 <- lm(LBXIN ~ URXOP4.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno4 <- lm(LBXIN ~ URXOP4.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes4), 2)
round(confint(model.alcyes4), 2)
round(coef(model.alcno4), 2)
round(confint(model.alcno4),2)
#DMDTP
model.alcyes5 <- lm(LBXIN ~ URXOP5.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno5 <- lm(LBXIN ~ URXOP5.log,
data = lab_activity_5[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes5), 2)
round(confint(model.alcyes5), 2)
round(coef(model.alcno5), 2)
round(confint(model.alcno5),2)
#DMTP
model.alcyes3 <- lm(LBXIN ~ URXOP3.log,
data = mixture[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno3 <- lm(LBXIN ~ URXOP3.log,
data = mixture[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes3), 2)
round(confint(model.alcyes3), 2)
round(coef(model.alcno3), 2)
round(confint(model.alcno3),2)
#DEP
model.alcyes2 <- lm(LBXIN ~ URXOP2.log,
data = mixture[which(mixture$ALQ111 == 1),]
)
model.alcno2 <- lm(LBXIN ~ URXOP2.log,
data = mixture[which(mixture$ALQ111 ==0),]
)
round(coef(model.alcyes2), 2)
round(confint(model.alcyes2), 2)
round(coef(model.alcno2), 2)
round(confint(model.alcno2),2)
#DMTP
model.alcyes3 <- lm(LBXIN ~ URXOP3.log,
data = mixture[which(mixture$ALQ111 == 1),]
)
model.alcno3 <- lm(LBXIN ~ URXOP3.log,
data = mixture[which(mixture$ALQ111 ==0),]
)
round(coef(model.alcyes3), 2)
round(confint(model.alcyes3), 2)
round(coef(model.alcno3), 2)
round(confint(model.alcno3),2)
View(m1)
#DETP
model.alcyes4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes4), 2)
round(confint(model.alcyes4), 2)
round(coef(model.alcno4), 2)
round(confint(model.alcno4),2)
#DETP
model.alcyes4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(lab_activity_5$ALQ111 == 1),]
)
model.alcno4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(lab_activity_5$ALQ111 ==0),]
)
round(coef(model.alcyes4), 2)
round(confint(model.alcyes4), 2)
round(coef(model.alcno4), 2)
round(confint(model.alcno4),2)
model.alcyes4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(mixture$ALQ111 == 1),]
)
model.alcno4 <- lm(LBXIN ~ URXOP4.log,
data = mixture[which(mixture$ALQ111 ==0),]
)
round(coef(model.alcyes4), 2)
round(confint(model.alcyes4), 2)
round(coef(model.alcno4), 2)
round(confint(model.alcno4),2)
model.alcyes5 <- lm(LBXIN ~ URXOP5.log,
data = mixture[which(mixture$ALQ111 == 1),]
)
model.alcno5 <- lm(LBXIN ~ URXOP5.log,
data = mixture[which(mixture$ALQ111 ==0),]
)
round(coef(model.alcyes5), 2)
round(confint(model.alcyes5), 2)
round(coef(model.alcno5), 2)
round(confint(model.alcno5),2)
#DMP
model.interaction1<- lm(LBXIN ~ URXOP1.log + URXOP1.log*ALQ111,
data = mixture)
summary(model.interaction1)
#DEP
model.interaction2<- lm(LBXIN ~ URXOP2.log + URXOP2.log*ALQ111,
data = mixture)
summary(model.interaction2)
#DMTP
model.interaction3<- lm(LBXIN ~ URXOP3.log + URXOP3.log*ALQ111,
data = mixture)
summary(model.interaction3)
#DETP
model.interaction4<- lm(LBXIN ~ URXOP4.log + URXOP4.log*ALQ111,
data = mixture)
summary(model.interaction4)
#DMDTP
model.interaction5<- lm(LBXIN ~ URXOP5.log + URXOP5.log*ALQ111,
data = mixture)
summary(model.interaction5)
df.exp <- mixture |>
select(URXOP1.log, URXOP2.log, URXOP3.log, URXOP4.log, URXOP5.log)
set.seed(111)
fit_int <- kmbayes(y = mixture$LBXIN,
Z = df.exp,
iter = 100,
verbose = FALSE,
varsel = TRUE,
family = 'gaussian')
qgc.intx <- qgcomp.emm.glm.noboot(LBXIN ~ URXOP1.log + URXOP2.log + URXOP3.log + URXOP4.log
+URXOP5.log,
expnms = exposure.names,
dat = mixture,
family = gaussian(),
emmvar = "ALQ111",
q = 4)
getstrateffects(qgc.intx, emmval = 0)
getstrateffects(qgc.intx, emmval = 1)
qgc.intx
pred.resp.bivar <- PredictorResponseBivar(fit=fit_int, min.plot.dist = 1)
pred.resp.bivar.levels <-
PredictorResponseBivarLevels(pred.resp.df =
pred.resp.bivar,
Z = as.matrix(df.exp),
qs = c(.25, .5, .75))
ggplot(pred.resp.bivar.levels, aes(z1, est)) +
geom_smooth(aes(col = quantile), stat = "identity") +
facet_grid(variable2 ~ variable1) +
ggtitle("h(expos1 | quantiles of expos2") +
xlab("expos1")
setwd("~/LOTR_data")
library(readr)
library(dplyr)
library(gtsummary)
here::i_am(
"Lotr_code.Rmd"
)
lotr<- read.csv("lotr_characters.csv")
here::i_am(
"code/code1"
)
here::i_am(
"code/code1.R"
)
library(readr)
library(dplyr)
library(stringr)
library(gtsummary)
lotr<- read.csv("lotr_characters.csv")
lotr <- lotr %>%
mutate(
gender = str_to_lower(gender),
gender = if_else(str_detect(gender, "male"), "Male",
if_else(str_detect(gender, "female"), "Female", NA_character_))
)
table_LOTR_Race <- lotr |>
select("race", "gender") |>
tbl_summary(
by = race,
include = gender,
missing= "no",
label = list(gender~"Gender")
) |>
modify_spanning_header(
all_stat_cols() ~ "**Race**"
) %>%
add_overall() %>%
modify_caption("**Gender distribution by Race**")
table_LOTR_Race
saveRDS(
table_LOTR_Race,
file = here::here("output", "table_LOTR_Race.rds")
)
here::here("output/table_LOTR_Race.rds")
#data cleaning
#library(stringr)
#lotr <- lotr %>%
#  mutate(
#    gender = str_to_lower(gender),
#    gender = if_else(str_detect(gender, "male"), "Male",
#                     if_else(str_detect(gender, "female"), "Female", NA_character_))
#  )
#table_LOTR_Race <- lotr |>
#  select("race", "gender") |>
#  tbl_summary(
#    by = race,
#    include = gender,
#    missing= "no",
#    label = list(gender~"Gender")
#  ) |>
#   modify_spanning_header(
#    all_stat_cols() ~ "**Race**"
#  ) %>%
#  add_overall() %>%
#  modify_caption("**Gender distribution by Race**")
#  table_LOTR_Race
here::here("output/table_LOTR_Race.rds")
table_LOTR_Race
#data cleaning
#library(stringr)
#lotr <- lotr %>%
#  mutate(
#    gender = str_to_lower(gender),
#    gender = if_else(str_detect(gender, "male"), "Male",
#                     if_else(str_detect(gender, "female"), "Female", NA_character_))
#  )
#table_LOTR_Race <- lotr |>
#  select("race", "gender") |>
#  tbl_summary(
#    by = race,
#    include = gender,
#    missing= "no",
#    label = list(gender~"Gender")
#  ) |>
#   modify_spanning_header(
#    all_stat_cols() ~ "**Race**"
#  ) %>%
#  add_overall() %>%
#  modify_caption("**Gender distribution by Race**")
#  table_LOTR_Race
ggplot(lotr, aes(x = race))+
geom_bar()+   # histogram of categorical variable = bar chart
labs(
title = "Distribution of Characters by Race",
x = "Race",
y = "Count"
)+
theme(axis.text.x = element_text(angle = 45))
LOTR_Race_Dist <- ggplot(lotr, aes(x = race))+
geom_bar()+   # histogram of categorical variable = bar chart
labs(
title = "Distribution of Characters by Race",
x = "Race",
y = "Count"
)+
theme(axis.text.x = element_text(angle = 45))
saveRDS(
LOTR_Race_Dist,
file = here::here("output", "LOTR_Race_dist.rds")
)
here::here("output/LOTR_Race_Dist")
LOTR_Race_Dist
here::here("output/LOTR_Race_Dist")
LOTR_Race_Dist
here::i_am(
"code/02_render_report.R"
)
rmarkdown::render(
here::here("Lotr_code.Rmd")
)
make
install.packages("here")
setwd("~/Docker_and_R")
renv::init()
renv::snapshot()
setwd("~/LOTR_data")
renv::init()
renv::snapshot()
